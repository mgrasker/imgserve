#!/usr/bin/env python3
from __future__ import annotations
import argparse
from datetime import datetime
from pathlib import Path

from imgserve.vectors import get_vectors


def name_to_dict(name: str) -> Dict[str, Any]:
    dimensions = [pair.split("=") for pair in name.split("|")]
    return {key: val for key, val in dimensions}


def main(downloads: Path, date_field: str, group_by_field: str) -> None:
    bucket_size = 100

    buckets_root = downloads.parent.joinpath("date-buckets")
    buckets_root.mkdir(exist_ok=True, parents=True)

    terms = set()
    for folder in sorted(downloads.glob(f"*")):
        dimensions = name_to_dict(folder.name)
        terms.add(dimensions[group_by_field])

    for term in terms:
        init = True
        for folder in reversed(sorted(downloads.glob(f"*{term}*"))):
            dimensions = name_to_dict(folder.name)

            if init or len(list(bucket.iterdir())) >= bucket_size:
                start = datetime.fromtimestamp(
                    int(dimensions[date_field]) / 1000
                ).date()
                bucket = buckets_root.joinpath(
                    f"{group_by_field}={dimensions[group_by_field]}|{date_field}={start}"
                )
                bucket.mkdir(exist_ok=True, parents=True)
                print(term, start)
                init = False

            for img in folder.iterdir():
                bucket.joinpath(img.name).write_bytes(img.read_bytes())

    vectors_path = downloads.parent.joinpath("vectors")
    vectors_path.mkdir(exist_ok=True, parents=True)
    for vector, metadata in get_vectors(buckets_root):
        vector.colorgram.save(vectors_path.joinpath(f"{vector.word}.png"))

    print(f"vectors saved: {downloads.joinpath('vectors')}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--downloads",
        type=Path,
        help="Path to downloads folder generated by splitting with last_modified dimension",
    )
    parser.add_argument(
        "--date-field",
        default="headers.last_modified",
        help="name of date dimension to create uniform sized buckets from",
    )
    parser.add_argument(
        "--group-by-field",
        default="query",
        help="field accross which buckets will be grouped",
    )
    args = parser.parse_args()

    main(
        downloads=args.downloads,
        date_field=args.date_field,
        group_by_field=args.group_by_field,
    )
